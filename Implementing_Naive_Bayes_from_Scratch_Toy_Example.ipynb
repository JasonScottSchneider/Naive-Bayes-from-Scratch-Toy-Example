{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solid-double",
   "metadata": {},
   "source": [
    "## Naive Bayes from Scratch Toy Example\n",
    "<p>This is a toy example using Naive Bayes. The program below is not novel, but this is a great way to learn how to do machine learning without additional modules. I mean, we do want to learn how this thing works, right?</p>\n",
    "<p>Let's play!</p>\n",
    "<p>Let's say we have four people who reviewed movies, the liked and disliked marked by 0 for dislike and 1 for like as well as Y for like and N for dislike of a target movie. Then we get a fifth person who has given likes and dislikes for each of the three movies, but we don't know what that person's review for a target movie is. We want to predict whether that fifth movie reviewer will give Y or N for a target movie; thus we use Naive Bayes from scratch--no modules such as Sklearn and such--because we want to learn how Naive Bayes ticks.</p>\n",
    "<p>I try to explain in plain English how this works from scratch as a layman, so, hopefully, others might enjoy grasping how Naive Bayes actually works like me.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fantastic-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "In the array for X_train, each list contains a 1 for like and 0 for dislike for some movies, which are features to predict whether that person likes the target movie indicated with Y or N in the list Y_train.\n",
    "We are given a fifth person's likes and dislikes for some movies, and we will use those features to predict whether that person will like the target movie.\n",
    "We already have our toy data divided up into training and testing sets, so let's go.\n",
    "\"\"\"\n",
    "\n",
    "X_train = np.array([\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 0]])\n",
    "\n",
    "Y_train = ['Y', 'N', 'Y', 'Y']\n",
    "\n",
    "X_test = np.array([[1, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polished-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_indices(labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    We will use defaultdict to avoid getting key errors when different keys have the same values.\n",
    "    We cannot avoid key errors using regular dictionaries in python, so we must use defaultdict instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    label_indices = defaultdict(list)\n",
    "    for index, label in enumerate(labels):\n",
    "        label_indices[label].append(index)\n",
    "    return label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspended-attachment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_indices:\n",
      " defaultdict(<class 'list'>, {'Y': [0, 2, 3], 'N': [1]})\n"
     ]
    }
   ],
   "source": [
    "label_indices = get_label_indices(Y_train)\n",
    "print('label_indices:\\n', label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amazing-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(label_indices):\n",
    "    \n",
    "    \"\"\"\n",
    "    Basically, this computes the prior by P(Y) and P(N).\n",
    "    \"\"\"\n",
    "    \n",
    "    prior = {label: len(indices) for label, indices in label_indices.items()}\n",
    "    total_count = sum(prior.values())\n",
    "    for label in prior:\n",
    "        prior[label] /= total_count\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romance-potter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: {'Y': 0.75, 'N': 0.25}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We need to compute the prior assumption of Y and N.\n",
    "P(Y) = 3/4 because there is Y, Y, Y, and N, making three Y's out of four targets.\n",
    "P(N) = 1/4 because there is only one N out of four targets.\n",
    "\"\"\"\n",
    "\n",
    "prior = get_prior(label_indices)\n",
    "print('Prior:', prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behavioral-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_likelihood(features, label_indices, smoothing=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    The likelihood is a conditional probability in which P(feature|class).\n",
    "    \"\"\"\n",
    "    \n",
    "    likelihood = {}\n",
    "    for label, indices in label_indices.items():\n",
    "        likelihood[label] = features[indices, :].sum(axis=0) + smoothing\n",
    "        total_count = len(indices)\n",
    "        likelihood[label] = likelihood[label] / (total_count + 2 * smoothing)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunrise-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood:\n",
      " {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "          m1, m2, m3\n",
    "person 1: [0, 1, 1] = Y\n",
    "person 2: [0, 0, 1] = N\n",
    "person 3: [0, 0, 0] = Y\n",
    "person 4: [1, 1, 0] = Y\n",
    "\n",
    "m1=f1,m2=f2,m3=f3\n",
    "\n",
    "For f1, we have 1 like out of 0, 0, 1 for Y.\n",
    "We have +1 for smoothing in the numerator and +2 in the denominator (i.e., two possible outcomes being Y and N).\n",
    "Therefore P(f1/N) = 0 likes + 1 smoothing / 1 data point + 2 possibilities = 1/3 = 0.33333333333\n",
    "P(f1/Y) = 1 like + 1 smoothing / 3 data points + 2 possibilities = 2/5 = 0.4\n",
    "P(f2/N) = 0 likes + 1 smoothing / 1 data point + 2 possibilities = 1/3 = 0.33333333333\n",
    "P(f2/Y) = 2 likes + 1 smoothing / 3 data points + 2 possibilities = 3/5 = 0.6\n",
    "P(f3/N) = 1 like + 1 smoothing / 1 data point + 2 possibilities = 2/3 = 0.66666667\n",
    "P(f3/Y) = 1 like + 1 smoothing / 3 data points + 2 possibilities = 2/5 = 0.4\n",
    "\n",
    "          m1, m2, m3\n",
    "person 5: [1, 1, 0] = ?\n",
    "Now, will person 5 like or dislike a target movie, indicated with Y or N?\n",
    "This is what we will use Naive Bayes for to answer this question.\n",
    "\"\"\"\n",
    "\n",
    "smoothing = 1\n",
    "likelihood = get_likelihood(X_train, label_indices, smoothing)\n",
    "print('Likelihood:\\n', likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frank-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(X, prior, likelihood):\n",
    "    \"\"\"\n",
    "    P(N)*P(f1=1|N)*P(f2=1|N)*P(f3=0|N) = P(N|x of X_train)\n",
    "    P(Y)*P(f1=1|Y)*P(f2=1|Y)*P(f3=0|Y) = P(Y|x of X_train)\n",
    "    \n",
    "    P(Y|x of X_train) + P(N|x of X_train) = sum\n",
    "    \n",
    "    P(Y|x of X_train) / sum = the assumption of like for target movie by fifth person\n",
    "    P(M|x of X_train) / sum = the assumption of dislike for target movie by fifth person\n",
    "    \"\"\"\n",
    "    posteriors = []\n",
    "    for x in X: # [1, 1, 0]\n",
    "        #print(\"x: \",x)\n",
    "        # posterior is proportional to prior * likelihood\n",
    "        posterior = prior.copy() # Prior: {'Y': 0.75, 'N': 0.25}\n",
    "        #print(\"posterior: \",posterior)\n",
    "        for label, likelihood_label in likelihood.items(): # {'Y': array([0.4, 0.6, 0.4]), 'N': array([0.33333333, 0.33333333, 0.66666667])}\n",
    "            #print(\"label and likelihood_label: \",label,likelihood_label)\n",
    "            for index, bool_value in enumerate(x):\n",
    "                #print(\"index and bool_value: \",index,bool_value)\n",
    "                #print(\"likelihood_label[index]: \",likelihood_label[index])\n",
    "                posterior[label] *= likelihood_label[index] if bool_value else (1 - likelihood_label[index])\n",
    "                #print(\"posterior[label]: \",posterior[label])\n",
    "        # normalize so that all sums up to 1\n",
    "        #print(\"posterior.values(): \",posterior.values())\n",
    "        sum_posterior = sum(posterior.values())\n",
    "        #print(\"sum_posterior\",sum_posterior)\n",
    "        for label in posterior:\n",
    "            if posterior[label] == float('inf'): # infimum\n",
    "                posterior[label] = 1.0\n",
    "            else:\n",
    "                posterior[label] /= sum_posterior\n",
    "        posteriors.append(posterior.copy())\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "emotional-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior:\n",
      " [{'Y': 0.9210360075805433, 'N': 0.07896399241945673}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute the posterior\n",
    "\n",
    "Step 1: posterior[label] *= likelihood_label[index] if bool_value else (1 - likelihood_label[index])\n",
    "\n",
    "Do for Y:\n",
    ".75*.4 (because X_test[0] is 1, thus true) \n",
    "= 0.30000000000000004*.6(because X_test[1] is 1, thus true)\n",
    "= 0.18000000000000002*(1-.4) (because X_test[2] is 0, thus false)\n",
    "= 0.10800000000000001 = Y\n",
    "\n",
    "Do for N:\n",
    ".25*0.3333333333333333 (because X_test[0] is 1, thus true)\n",
    "= 0.08333333333333333*0.3333333333333333 (because X_test[1] is 1, thus true)\n",
    "= 0.027777777777777776*(1-0.6666666666666666)  (because X_test[2] is 0, thus false)\n",
    "= 0.00925925925925926 = N\n",
    "\n",
    "Step 2: sum_posterior = sum(posterior.values())\n",
    "0.10800000000000001+0.00925925925925926 = 0.11725925925925927\n",
    "\n",
    "Step 3: posterior[label] /= sum_posterior\n",
    "\n",
    "Do for Y:\n",
    "0.10800000000000001 / 0.11725925925925927 = 0.9210360075805433 = Y\n",
    "\n",
    "Do for N:\n",
    "0.00925925925925926 / 0.11725925925925927 = 0.07896399241945673 = N\n",
    "\"\"\"\n",
    "\n",
    "posterior = get_posterior(X_test, prior, likelihood)\n",
    "print('Posterior:\\n', posterior)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
